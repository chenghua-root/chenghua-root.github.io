---  
layout: post  
title:  "事务原理及实现机制"  
date:   2019-08-20 21:03:36 +0530   
---  
本文为作者在美团对象存储组关于数据库事务所做的分享。  
文章有少量调整：删除了对美团分布式数据库Blade事务实现（设计未公开）的分析，新增了对OceanBase(v.0.5.0)和sqlite事务实现的介绍。  
  
## 文章要点
- 论述了ACID的关系：**即原子性、隔离性和持久性都是为了保证一致性。**  
- 讨论了保证一致性的手段：**通过锁或者版本号。**
- 重点分析了：
  - **为什么两阶段读写锁能保证一致性并给出了证明。**
  - **如何使用版本号来保证一致性。**

## 什么是事务  
  事务是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。  
  事务需作为一个原子被孤立地执行。  
  任何一个查询或修改动作本身就可以是一个事务。  
  
## 为什么需要事务  
  举例1：  
  A给B转账100元，若在A扣除100元后系统宕机。则存在：A减掉了100元，B却未加上100元。  
  可以把这个转账操作称为一个事务，则这个事务需要全部完成，或者全部不完成。  
  即事务需要被原子执行。  
  
  举例2：  
  A和B同时给C转账100元。C可能增加了100元，也可能增加200元。（比如，C账户数据在磁盘上，需要读取上来增加100后再写回）  
  事务需要被孤立的执行，即事务执行期间互相不影响。至少是“看上去”像只有本事务在执行。  
  
## 事务特性  
  为了解决以上例子面临的问题，对事务规定了如下要求：  
  - 原子性：事务包含一个或多个步骤，必须作为一个整体执行或根本不执行。不能只执行部分。  
  - 一致性：事务应确保数据库的状态从一个一致状态转变为另外一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。  
  - 隔离性：并发事务。数据库允许多个事务并发执行，隔离性可以防止多个事务并发执行时由于交叉执行而导致的数据不一致。  
  - 持久性：已被提交的事务对数据库的修改应该永久保存在数据库中。  
  
**ACID关系：**  
  - **在事务处理的ACID属性中，一致性是最基本的属性，其它的三个属性都为了保证一致性而存在的。**  
  所谓一致性，指的是数据处于一种有意义的状态，这种状态是语义上的而不是语法上的。最常见的例子是转帐。例如从帐户A转一笔钱到帐户B上，如果帐户A上的钱减少了，而帐户B上的钱却没有增加，那么我们认为此时数据处于不一致的状态。  
  
  - 在数据库实现的场景中，一致性可以分为数据库外部的一致性和数据库内部的一致性。前者由外部应用的编码来保证，即某个应用在执行转帐的数据库操作时，必须在同一个事务内部调用对帐户A和帐户B的操作。如果在这个层次出现错误，这不是数据库本身能够解决的，也不属于我们需要讨论的范围。后者由数据库来保证，即在同一个事务内部的一组操作必须全部执行成功（或者全部失败）。这就是事务处理的原子性。  
  为了实现原子性，需要通过日志：将所有对数据的更新操作都写入日志，如果一个事务中的一部分操作已经成功，但以后的操作，由于断电/系统崩溃/其它的软硬件错误而无法继续，则通过回溯日志，将已经执行成功的操作撤销，从而达到“全部操作失败”的目的。  
  
  - 但是，原子性并不能完全保证一致性。在多个事务并行进行的情况下，即使保证了每一个事务的原子性，仍然可能导致数据不一致的结果。例如，事务1需要将100元转入帐号A：先读取帐号A的值，然后在这个值上加上100。但是，在这两个操作之间，另一个事务2修改了帐号A的值，为它增加了100元。那么最后的结果应该是A增加了200元。但事实上， 事务1最终完成后，帐号A只增加了100元，因为事务2的修改结果被事务1覆盖掉了。  
  为了保证并发情况下的一致性，引入了隔离性，即保证每一个事务能够看到的数据总是一致的，就好象其它并发事务并不存在一样。用术语来说，就是多个事务并发执行后的状态，和它们串行执行后的状态是等价的。  
  
## 原子性  
### 如何保证原子性  
  事务在执行过程中，可能因为服务程序退出、系统故障等导致事务只执行了部分，从而不满足原子性。  
  如何保证事务必须原子的执行，即全做或全不做，并且在时间上看上去似乎是在某个时刻瞬间完成的。  
  保证事务正确执行是事务管理器的工作，事务管理子系统完成的功能包括：  
  - 使用日志保证原子性：给日志管理器发信号，使必须的信息以日志记录的形式存储在日志中。  
  - 通过并发控制来保证隔离性：保证并发执行的事务不会以引入错误的方式相互干扰（见后面并发控制）  
  
  本节主要讨论如何使用日志来保证原子性。  
  
### 事务的原语操作  
  事务需要原子的执行，但事务本身是包含一个或多个操作的，每个操作被定义为一个原语。下面详细列出事务是如何同数据库交互的。  
  1. 保存数据库元素的磁盘块空间。  
  2. 缓冲区管理器所管理的主存地址空间。  
  3. 事务的局部地址空间。  
  
  事务要读取数据库元素，该元素必须先读取到主存的一个或多个缓冲区中。接下来，缓冲区的内容可以被事务读到其局部地址空间中。事务为数据库元素写入一个新值的过程相反。  
  
  缓冲区中的内容可能是也可能不是被立即拷贝到磁盘。基于可恢复性和性能方面，会选择适当的时机把缓冲区数据更新到磁盘。  
  
  后面讨论使用的原语包括：  
  * INPUT(X)：将包含数据库元素X的磁盘块拷贝到主存缓冲区  
  * READ(X, t)：将数据库元素X拷贝到事务局部变量t。若X不在缓冲区中，则首先执行INPUT(X)  
  * WRITE(X, t)：将局部变量t的值拷贝到主存缓冲区中的数据库元素X  
  * OUTPUT(X)：将包含X的缓冲区中的块拷贝回磁盘  
  
  问题：工程实现中是否一定需要缓冲区？  
  
<style>  
.tablelines table, .tablelines td, .tablelines th {  
  border: 1px solid black;  
  }  
</style>  
  
### 原语操作与事务操作的联系  
  举例，事务T逻辑上由下述两步构成：  
  * A := A * 2  
  * B := B * 2  
  一致性约束：事务执行前A = B，事务完成后A仍然等于B。  
  
  | 动作   | 局部地址空间t | 内存中的A | 内存中的B | 磁盘中的A | 磁盘中的B |  
  | -----  | ----  |  -----  |  -----  |  -----  |  -----  |  
  | READ(A,t)  | 8   | 8   |   |  8  |   8   |  
  | t := t * 2 | 16  | 16  |   | 8   | 8   |  
  | WRITE(A, t)| 16  | 16  |   | 8   | 8   |  
  | READ(B, t) | 8   | 8   | 8   | 8   | 8   |  
  | t := t * 2 | 16  | 16  | 8   | 8   | 8   |  
  | WRITE(B, t)| 16  | 16  | 16  | 8   | 8   |  
  | OUTPUT(A)  | 16  | 16  | 16  |  16   | 8   |  
  | OUTPUT(B)  | 16  | 16  | 16  | 16  | 16  |  
{: .tablelines}  
  
  如果所有的这些步骤都执行，数据库的一致性就能得到保证。如果在执行OUTPUT(A)之前发生了系统故障，磁盘上存储的数据不会受到影响，一致性不会受到影响。  
  
  **如果系统故障在OUTPUT(A)之后OUTPUT(B)之前发生，则数据一致性被破坏。**  
  
## 日志  
前面提到，我们可以通过日志来保证事务的原子性。如何利用日志来保证原子性？  
我们可以对每个可能改变一致性的操作进行日志记录，根据日志来进行恢复。  
根据不同的日志类型可以采取不同的恢复策略，这里主要列举UNDO和REDO日志：  
- UNDO日志：记录操作前的数据状态，当事务被中断执行后，我们根据日志恢复到执行前的状态。  
- REDO日志：记录事务完成后数据应该有的状态。当事务被中断执行后，根据REDO日志继续执行。  
  
**日志记录：**  
可以将日志看作一个只能查看或追加写的文件。当事务执行时，日志管理器负责在日志中记录每个重要的事件。日志记录形式：  
- <START T>: 这一记录表示事务T已开设  
- <COMMIT T>: 事务T已经成功完成并且对数据库元素不再会修改。事务T对数据库所做的任何更新都应记录到磁盘上。  
- <ABORT T>: 事务T不能成功完成。如果事务T中止，它所做的更新都不应该反映在磁盘上，若已经修改磁盘，则需要消除更新。  
  
### UNDO日志  
除了上面的日志记录，UNDO日志还有自己的更新日志记录。  
更新日志记录<T, X, v>：事务T改变了数据库元素X，而X原来的值是v。更新记录所反映的改变通常发生在主存中而不是磁盘上：即日志记录是对写入内存的WRITE动作做出的反应，而不是写入磁盘OUTPUT动作所做的反应。  
  
问题：日志记录与WRITE()和OUTPUT()的关系?  
  
**undo日志规则：**  
- U1：如果事务T改变了数据库元素X，那么形如<T, X, v>的日志记录必须在X的新值写到磁盘之前写到磁盘中。  
- U2：如果事务提交，则其COMMIT日志记录必须在事务改变的所有数据库元素先写到磁盘之后写到磁盘。  
  
日志与执行语句的顺序关系：  
  
  | 动作  | 局部地址空间t | 内存中的A | 内存中的B | 磁盘中的A | 磁盘中的B | 日志  |  
  | -----   | ----  |  -----  |  -----  |  -----  |  -----  | ----  |  
  |   |   |   |   |   |   | \<START T\> |  
  | READ(A,t)   | 8   | 8   |   |  8  |   8   |   |  
  | t := t * 2  | 16  | 16  |   | 8   | 8   |   |  
  | WRITE(A, t) | 16  | 16  |   | 8   | 8   | \<T, A, 8\> |  
  | READ(B, t)  | 8   | 8   | 8   | 8   | 8   |   |  
  | t := t * 2  | 16  | 16  | 8   | 8   | 8   |   |  
  | WRITE(B, t) | 16  | 16  | 16  | 8   | 8   | \<T, A, 8\> |  
  |**FLUSH LOG**|   |   |   |   |   |   |  
  | OUTPUT(A)   | 16  | 16  | 16  |  16   | 8   |   |  
  | OUTPUT(B)   | 16  | 16  | 16  | 16  | 16  |   |  
  |   |   |   |   |   |   | \<COMMIT T\>|  
{: .tablelines}  
  
**使用undo日志进行恢复：**  
区分已提交事务和未提交事务:  
 - 从上面的阐述可知，往前回溯日志，只要有<COMMIT T>日志记录，则表明事务T已经提交。  
 - 若在回溯的过程中发现了<START T>，但未有对应的<COMMIT T>记录，那么事务T未完成提交，其修改的数据存在一部分数据写入磁盘，另外一部分未写入的可能。  
 - 根据undo日志规则，需要撤销整个事务，即数据恢复到事务开始之前的状态。  
  
恢复方法:  
1. 由于可能有多个未提交的事务，甚至多个未提交事务修改了同一个元素，所以恢复顺序必须是有顺序的：从尾部（最新日志）开始扫描日志  
2. 如果T的COMMIT记录被扫描到，则什么也不做。  
3. 否则，T是一个未完成的事务，或一个中止事务。必须撤销修改的数据。对完成恢复的事务，记录日志<ABORT T>，表明事务已经被恢复过。  
  
**检查点：**  
上面的恢复方法需要回溯整个日志记录。避免方法是加入检查点，即检查点之前的日志已经全部完成提交。  
如何添加检查点：  
1. 停止接收新的事务  
2. 等到所有的当前活跃事务提交或中止并且在日志中写入COMMIT或ABORT记录  
3. 将日志刷新到磁盘  
4. 写入日志记录<CKPT>，并再次刷新日志  
5. 重新开始接收  
  
**非静止检查点：**  
上面的检查点为静止检查点，需要暂停新事务的执行，于是引入了非静止检查点。  
非静止检查点的思想为记录检查点日志<START CKPT(T1, ..., Tn)>，等待(T1, ..., Tn)都完成后记录<END CKPT(T1, ..., Tn)>。后续只需回溯到<START CKPT>或<START CKPT> + (T1, .., Tn)事务。  
  
### REDO日志  
除了undo日志，还可以通过redo日志或undo+redo日志来保证事务原子性。  
redo日志的原理跟undo类似，这里不再介绍。  
  
## 持久性  
持久性主要包括两点：  
1. 事务角度：提交的事务写回磁盘，或者宕机后能通过日志恢复  
2. 存储角度：保证写入的数据的可靠性。如：磁盘阵列，主备同步，多副本（raft/paxos）  
  
## 隔离性  
**隔离性是指事务并发执行时可能互相影响，根据不同的影响程度进行不同隔离级别的定义。**  
**如果事务是串行执行的，则在保证原子性和持久性的基础上就满足了事务的一致性。**后续的讨论将不再必要。  
  
但是，为了提高系统的事务处理能力，系统会并发的执行事务。在并发执行过程中，存在影响数据一致性的行为。  
不一致的表现如下：  
- 丢失更新：  
  - A和B同时给C转账100元。最后C只增加了100元。  
- 脏读：读取到未提交的数据  
  - A转账100元给账号B，在转账的同时计算A和B的余额之和。  

  |          | A = 1000 | B = 1000 | |  
  | -----    | ----     |  ---     | -----   |
  | T1:读取A | 1000     |          |  |
  | T1:读取B |          |1000      |  |  
  | T1:A-100 | 900      |          |  |
  | T1:计算A+B   | 900      | 1000     | <strong>A+B = 1900, 读到A未提交的数据<strong> |
  | T1:B+200 |          | 1100     |  |
  | T1:提交  | A=900    | B=1100   |  |
{: .tablelines}  

- 不可重复读：同一个事务两次读取同一行记录，返回的值不一致  

  |        | A = 1000 | |  
  | -----  | ----   |  --- |
  | T1: 读取A | 1000 | |  
  |T2: A+200并提交| A = 1200 | |  
  | T1：再次读取A| 1200 | <strong>两次读取A的值不一致，1000/1200<strong> |  
{: .tablelines}  

- 不可重复读2：  

  |        | A = 1000 | B = 1000 | |  
  | -----  | ----   |  --- |  -----   |
  | T1:读取A| 1000 |  |  |
  | T2: A给B转账200| A=800 |  B=1200 ||  
  | T1:读取B| | 1200 |  |
  | T1: 计算A+B| |  | <strong>sum=2200<strong> |
{: .tablelines}  


- 幻读:  

  |          |          |
  | -----    | ----     |
  | T1: 统计余额在[1000, 2000)的账户个数 |  select count(\*) from table where value >= 1000 and value < 2000; count(\*) = 10|
  | T2: 插入一条余额为1500的新记录 |          |
  |  T1: 继续重新统计余额在[1000, 2000)的账户个数|     <strong>count(\*) = 11<strong> |
{: .tablelines}  

### 隔离级别：  
根据如上几种不一致的表现定义了如下几种隔离级别：  
  
  | 隔离级别 | 丢失更新 | 脏读 | 不可重复读 | 幻读   |  
  | -----  | ----   |  --- |  -----   | -----  |  
  | 覆盖写 | 可能| 可能 | 可能  | 可能|  
  | 读未提交| 不可能| 可能 | 可能  | 可能|  
  | 读已提交 | 不可能| 不可能 | 可能  | 可能|  
  | 可重复读| 不可能| 不可能 | 不可能  | 可能|  
  | 可串行化| 不可能| 不可能 | 不可能  | 不可能|  
{: .tablelines}  
  
读已提交是所有OLTP数据库系统（MySQL, Oracle, OceanBase, TiDB）最低的隔离级别。  
不同数据库系统支持的隔离级别：  
- MySQL：RC、RR  
- OceanBase：RC  
- TiDB：SI，可称为RR   (TiDB 事务隔离级别)[https://pingcap.com/docs-cn/v3.0/reference/transactions/transaction-isolation/]  
  
为了使事务在并发执行过程中避免不一致的行为，即满足一定的隔离级别，需要对事务执行进行调度，即并发控制。  
更详细的隔离级别分享参考[数据库事务隔离标准分析](http://oceanbase.org.cn/?p=281)  
  
## 并发控制  
  
什么是并发控制？  
- 不同事务各个步骤的执行顺序必须以某种方式进行规范，该规范由调度器部件完成，保证并发执行的事务能保持一致性的整个过程称为并发控制。  
  
串行调度：  
- 即为事务一个一个的执行。  
  
可串行化调度：  
- 对于每个数据库初态，若调度S和串行调度S'的效果一致，则S是可串行化的。  
  
冲突可串行化调度：  
- 如果通过一系列相邻动作的非冲突交换能将它们中的一个转换为另外一个，我们说两个调度是冲突等价的。  
- **如果一个调度冲突等价于一个串行调度，那么我们说该调度是冲突可串行化的。**  
- 冲突：  
  - 不同事务的操作涉及同一数据库元素  
  - 至少有一个是写操作  
- 举例：  
  - 调度：r1(A); w1(A); r2(A); w2(A); r1(B); w1(B); r2(B); w2(B);  
  - 可调整为：r1(A); w1(A); r1(B); w1(B); r2(A); w2(A); r2(B); w2(B);  
  
## 使用锁的并发控制  
在探索使用锁来实现可串行化之前，先列出所有的锁。  
锁的分类：  
 - 属性锁：共享锁（读锁）、排他锁（写锁）、更新锁、增量锁;  
 - 锁范围：行锁、表锁、页锁、间隙锁  
 - 状态锁：意向锁  
 - 锁模型：两阶段锁  
  
### 锁  
在操作对应的数据前，先申请锁，申请成功后再执行。  
锁能解决的问题：  
 - 加写锁：更新的时候加锁。解决丢失更新的问题，但不能解决读未提交的数据。  
 - 写锁+提交位：写的时候加锁，读的时候根据提交位避免读取未提交的数据，缓存中保存了未提交的数据和之前已经提交的数据。解决读未提交的数据，但不能解决无法重复读的问题。  
 - 读锁+写锁：读的时候加读锁，写的时候加写锁。解决了不能重复读的问题，但不能解决幻读的问题。  
 - 读锁+写锁+间隙锁：解决了幻读的问题。  
  
问题：  
- 为什么加读写锁后能保证一致性？(参考两阶段锁的证明。)  
  
### 两阶段锁  
**即使在有锁的情况下仍然不能保证调度是可串行化的。**  
  
先定义锁原语：  
- L1(X)：事务1对元素X申请锁  
- U1(X)：事务1对元素X释放锁  
举例：  
- 初始值A=25, B=25。事务T1: A+100, B+100，事务T2：A=A\*2, B=B\*2。一致性约束: A = B  
  
  |   T1  |  T2   |  A的值   |   B的值   |  
  |   ---   |   ---   |   ---   |   ---   |  
  |   |   |   25  |   25  |  
  |  L1(A); r1(A);  A := A+100;  w1(A); u1(A);   |   |   125  |   |  
  |   |   L2(A); r2(A); A := A \* 2; w2(A); u2(A);  |  250   |  |  
  |   |   L2(B); r2(B); B := B\*2; w2(B); u2(B);  |   |  50  |  
  | L1(B); r1(B); B := B+100; w1(B); u1(B);  |   |   |  150  |  
{: .tablelines}  
  
解决方法：  
- 事务申请锁后直到事务结束才释放锁。  
- 这样锁的粒度太大，更好的方法是申请锁并完成相应操作后，如果本事务后续不再申请新的锁，则可以释放掉此锁。  
  
在每个事务中，所有封锁请求先于所有解锁请求，即为两阶段锁。  
  
两阶段封锁发挥作用的原因：  
- **如果一个调度通过两阶段进行封锁，则可以把此调度通过冲突等价转换为一个串行调度。**  
- 通过归纳法来证明。  
  - 一个调度S包含n个事务。  
  - 基础：若n=1。则S已经是一个串行调度。  
  - 归纳：  
  - 假设S包含的n个事务分别为T1, T2, ..., Tn，并设Ti是在整个S中有第一个解锁动作的事务，例如Ui(X)。  
  - 断言：将Ti的所有动作不经过任何有冲突的读或写而向前移动到调度的开始是可能的。  
  - 考虑Ti的某个动作，例如Wi(Y)。S中这一动作前可能有冲突的动作，如Wj(Y)或Rk(Y)。这里以Wj(Y)举例，那么在调度S中，Uj(Y)和Li(Y)必然交错出现在这样一个动作序列中：  
  - ...Wj(Y), ..., Uj(Y), ..., Li(Y), ..., Wi(Y), ..., Ui(Y), ...  
  - 既然Ti是第一个解锁的事务，S中的Ui(Y)必然在Uj(Y)前，与假设冲突。  
  - 则可以把Ti的操作移动到前面，(Ti的操作)(其它n-1个事务的操作)。然后可通过递归的方法把剩下的n-1个事务也调整为串行事务。  
  
总结：  
 - **如果一个调度，采用两阶段锁协议，在操作之前加锁成功，则此调度是冲突可串行化的，满足可串行化隔离级别。**  
  
### 有多种属性锁模式的封锁系统  
  为了满足一致性，操作需要加锁，锁会带来阻塞。为了减少锁的粒度（即封锁窗口），常用方法为读写锁模式。除了读写锁，是否还有进一步缩小锁窗口的其它锁？  
  
**更新锁：**  
  - 事务更新某条记录时，若需要先读取，计算后再回写。由于需要更新，则按理需申请写锁。若此时记录被读锁占有，则申请写锁失败。  
  - **事务的前半段只涉及到读取记录和计算记录，是否可以先把记录读取并完成计算后再申请写锁。这里引入更新锁的概念。**  
  - 事务读取记录X时先申请更新锁，做计算后，更新锁升级为写锁后再写入记录。  
  - 记录有读锁时，可申请更新锁，有更新锁后不能再申请其它锁。若之前有读锁，则读锁释放后更新锁可以升级到写锁。  
  - 作用：  
  - 当记录被读锁占领时，若事务操作为读取元素计算后再修改。则可以申请更新锁，能够先把需要计算的记录读取上来。  
  
**增量锁：**  
  - 若只对某个元素做数字增加或减少，则可以申请增量锁。增量锁跟其它锁互斥。但增量锁互相不互斥。  
  - 作用：  
  - 多个事务可以同时对某个记录做增量。  
  
**封锁粒度：**  
上面讨论的封锁粒度为一条记录。除此之外，封锁粒度还可以为：  
 - 一个物理页面。  
 - 一个范围内的记录。  
 - 整个表。  
  
可以利用间隙锁来封锁一个范围的记录来解决幻读的问题。  
  
**树操作锁：**  
当索引是利用B+树来构造时，当我们删除/新增记录时，需要锁住整个B+树。  
锁粒度偏大，需要探索如何降低B+树的锁粒度。  
  
## 使用时间戳的并发控制  
**除了锁之外，还可以利用时间戳来保证事务的可串行性。**后面讨论中会混用事务版本号，时间戳和事务版本号是一致概念。  
时间戳的思想：  
 - **每个事务分配一个唯一递增的时间戳。这个时间戳就代表了当时事务的唯一View，也被称为事务的版本号。只要事务操作的数据满足这个View就满足了可串行性。即事务被一个唯一的点（时间戳）代替。**  
时间戳：  
 - 可以利用分散的原子时钟（spanner）或者统一授时的方式给分配时间戳（TiDB）。原子时钟不能严格保证递增，需要做一定的处理，暂不讨论。本文以统一授时为例分析讨论。  
  
时间戳把事务的多个操作“缩”为一个点的View，会存在哪些问题呢？  
时间戳存在的问题：  
1. 过晚的读：  
 - 事务T读取在T开始后被提交的数据。  
2. 过晚的写  
 - 事务T写 在T开始后被写过的记录。  
3. 脏数据  
 - 事务T读取未提交的数据。  
  
![时间戳存在的问题](https://chenghua-root.github.io/images/transaction-timestamp.png)  
  
### 基于时间戳的调度规则  
解决上述问题存在多种方式。  
其中一种解决方法为给每条记录添加三个标记。分别为：  
 - RT(X)：X当前最高的读时间戳。  
 - WT(X)：X当前最高的写时间戳。  
 - C(X)：X的提交位，该位为真，当且仅当最近写X的事务已经提交。  
  
然后结合这三个标记进行调度判定。  
  
调度规则：  
1. 当收到读X的请求rT(X):  
 a) 如果TS(T) >= WT(X)，则此读是允许的。  
  i. 如果C(X)为真，同意请求。如果TS(T) > RT(X)，置RT(X) := TS(T)。  
  ii. 如果C(X)为假，推迟T直到C(X)为真或写X的事务中止。  
 b) 如果TS(T) < WT(X)，此读不可实现。回滚T：中止事务T并以一个新的更大的时间戳重启它。  
2. 当收到写X的请求wT(X):  
 a) 如果TS(T) >= RT(X)，并且TS(T) >= WT(X)，则此写是可被执行的。  
  i.为X写入新值  
  ii. 置WT(X) := TS(T)  
  iii. 置C(X) := false  
 b) 如果TS(T) >= RT(X)，但是TS(T) < WT(X)，此写是事实上可行的。但X中已经有一个更晚的值。  
  i. 如果C(X)为真，那么更新的X的写已经提交。忽略此写请求即可  
  ii. 如果C(X)为假，我们必须推迟T，以防之前更新的写被回滚  
  注意：在系统实现中，由于没有保存记录的读时间戳，无法保证一致性。b)中行为会认为不可行，回滚事务。  
 c) 如果TS(T) < RT(X)，那么此写不被允许，必须回滚。  
3. 如果收到提交事务T的请求commit(T):  
  找到T写的所有数据库元素{X1, ..., Xn}，并置C(Xi) := true.  
  任何等待X被提交的事务则可以继续执行。  
4. 如果收到中止事务T的请求abort(T):  
  需要像1b和2c那样中止事务。  
  任何等待T所写的事务必须尝试重新读或写。  
  
### 多版本时间戳  
上面例子中1b、2b和2c为事务需要回滚的场景。并发度越大时，回滚/冲突的可能性越大，是否有可优化的空间？  
这里**利用多版本时间戳来解决1b的冲突：过晚的读。**  
多版本时间戳即每条记录不止保存当前最新的版本，也保留历史版本。  
具体方法：  
1. 当新的写wT(X)发生时，若合法，那么创建数据库元素X创建一个新的版本。其写时间戳为t = TS(T)，我们用Xt来代替它。  
2. 当rT(X)达到时，只需要读取Xt <= TS(T)的最新的版本的数据即可。  
3. 写时间与元素的版本相关，且保持不变。  
4. 读时间戳跟上面讨论的逻辑保持不变，阻止过晚的写.  
5. 当版本Xt的写时间t满足任何活跃事务的时间戳都不小于t时，我们就可以删除X的任何早于Xt的版本。  
  
**问题：没有读时间戳带来的影响：**  
- 为什么没有保留读时间戳？  
- 没有保留读时间戳对一致性有哪些影响？ (写偏序)   
  
**时间戳与封锁对比：**  
- 在大多数事务只读或并发事务极少试图读写同一元素的情况下，时间戳比较好。问题：为什么？  
- 在高冲突的情况下，封锁的性能较好。  
- 封锁在事务等待锁时通常推迟事务，但如果并发事务频繁读写公共元素，回滚就会很频繁，导致比封锁更多的延迟。  
  
**乐观锁：**  
- 如上基于时间戳的并发控制可以理解为乐观锁，乐观锁并不是一种锁，而是一种控制机制。相对封锁（悲观锁）而言被叫做乐观锁。  
- 乐观锁除了可通过时间戳实现外，还可以通过有效性确认来实现。  
- 有效性确认为在事务引擎中记录事务相关的信息（类似时间戳/版本等信息），在提交时进行确认的方式。由于使用有效性确认的系统不多，这里不再详述。  
- 这里只需要记住：**乐观锁是相对封锁（悲观锁）而言，时间戳+多版本是乐观锁的一种实现方式。**  
  
## 事务工程实现  
### 单机与分布式  
- 上面讨论了实现事务的两种方式：锁与时间戳。这两种方式都可以运用在单机和分布式中。  
- 单机和分布式的区别是，单机可以直接通过内存通信来获取资源（如：锁）或者是达成一致模型。而分布式系统中则需要通过网络通信来获取资源或者达成一致。  
- 单机和分布式本质上是一致的。  
- 分布式系统中获取资源或者达成一致协议的方式均可通过RPC请求实现。获取资源或者达成一致协议没有本质区别。都是在满足一定条件后继续下一步动作。  
- 工程实践中一般通过两阶段提交来达成一致协议。  
  
### 两阶段提交（2PC）  
两阶段提交（2 Phase Commit简称2PC）协议是用于在多个节点之间达成一致的通信协议，它是实现“有状态的”分布式系统所提出的经典解决方法。  
**两阶段提交和两阶段锁是不同的概念。**两阶段提交是一种协议，两阶段锁是一种规则。  
  
经典两阶段提交概述：两阶段协议包括一个协调者和多个参与者。  
1. 阶段1：  
 - 协调者向参与者发起prepare请求，然后等待参与者的回复。  
 - a) 若所有参与者都回复OK，则继续阶段2。  
 - b) 若有参与者回复not OK或者超时，则协调者向参与者发起abort请求。  
2. 阶段2：  
 - 协调者向参与者发起commit请求。  
  
这里有很多细节问题，暂不展开讨论，只列出几个问题：  
1. 参与者回复协调者OK后是否保证后面一直为可提交状态  
2. 参与者在阶段2崩溃  
3. 协调者在阶段1或阶段2崩溃  
  
### TiDB的事务模型  
  
TiDB的事务参照谷歌的Percolator，基于时间戳的并发控制+两阶段提交实现。  
TiDB事务详细设计参考[Transaction in TiDB](http://andremouche.github.io/tidb/transaction_in_tidb.html)  
隔离级别为SI。  
  
Percolator的核心思想：  
- 事务的提交状态跟primary record的提交状态保持一致。  
- 参与者记录primary record的key。在超时/宕机后通过查看primary record的状态来确定自己的状态。  
  
问题：  
- 为什么TiDB不适合秒杀场景?  
- 为什么Percolator需要两行{data行，提交行}来保存一条记录？  
  - Percolator存在startTS和commitTS两个时间戳，所以需要两行。且参与者记录的是primary的startTS索引，所以提交后也不能合并为一行  

Percolator详细分析参考[两阶段提交的工程实践](http://oceanbase.org.cn/?p=195)  
  
### OceanBase(v.0.5.0)的事务模型  
  
OceanBase(v.0.5.0)的事务基于锁实现。  
使用了MVCC技术实现只读与读写事务相互不阻塞。  
隔离级别为RC。  
详细实现参考[Oceanbase内存事务引擎](http://oceanbase.org.cn/?p=51)  
  
### sqlite的事务模型  
sqlite的事务基于锁（即悲观锁）实现。  
锁的粒度为数据库。  
包含共享锁，预留锁，未决锁，排它锁。  
- 预留锁和未决锁类似更新锁，为减少排它锁的范围。  
  
## 总结
- 本文首先分析了为什么需要事务以及事务的特性。阐述了原子性、一致性、隔离性和持久性的关系：**即原子性、隔离性和持久性都是为了保证一致性。**  
- 然后分析了如何实现保证原子性和持久性。原子性依赖日志，持久性依赖原子性和存储本身的可靠。  
- 其次分析了不一致的现象和隔离级别。  
- 再次分析了如何保证一致性：通过锁或者时间戳（事务版本）。重点分析了**为什么两阶段读写锁能保证一致性并给出了证明**，和**如何使用时间戳来保证一致性。**  
- 最后分析了TiDB、OceanBase和sqlite的事务实现方式。  
  
## 参考  
  数据库系统实现：https://book.douban.com/subject/4838430/  
  锁详解：https://blog.csdn.net/u010841296/article/details/84204701  
  Innodb中的事务隔离级别：https://tech.meituan.com/2014/08/20/innodb-lock.html  
  数据库事务隔离标准分析：http://oceanbase.org.cn/?p=281  
  两阶段提交的工程实践：http://oceanbase.org.cn/?p=195  
  B+树并发控制机制的前世今生: https://zhuanlan.zhihu.com/p/50112182
